{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c48154",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36185df8",
   "metadata": {},
   "source": [
    "- `import numpy as np`: This line imports the NumPy library, which provides support for efficient numerical operations in Python.\n",
    "- `import pandas as pd`: This line imports the Pandas library, which offers high-performance data manipulation and analysis tools for structured data.\n",
    "- `import matplotlib.pyplot as plt`: This line imports the `pyplot` module from the Matplotlib library, which provides a MATLAB-like interface for creating visualizations in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d1ce7b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(df):\n",
    "    # Convert categorical variables into numerical\n",
    "    df = pd.get_dummies(df)\n",
    "    \n",
    "    # Normalize numerical features\n",
    "    df = (df - df.mean()) / df.std()\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d39c3f0",
   "metadata": {},
   "source": [
    "Processing the Data (preprocess_data): The preprocess_data function takes a DataFrame (df) as input and performs preprocessing steps on the data. It first converts categorical variables into numerical representation using one-hot encoding through pd.get_dummies. Then, it normalizes the numerical features by subtracting the mean and dividing by the standard deviation. The preprocessed DataFrame is returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "60a53e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(df, test_size=0.2):\n",
    "    # Shuffle the DataFrame\n",
    "    df = df.sample(frac=1).reset_index(drop=True)\n",
    "    \n",
    "    # Split the DataFrame into training and testing sets\n",
    "    split_index = int((1 - test_size) * len(df))\n",
    "    train_data = df[:split_index]\n",
    "    test_data = df[split_index:]\n",
    "    \n",
    "    return train_data, test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e07c0079",
   "metadata": {},
   "source": [
    "Train-Test Split (train_test_split): The train_test_split function takes a DataFrame (df) and a test size ratio as inputs. It shuffles the rows of the DataFrame using sample and reset_index to ensure randomization. Then, it splits the shuffled DataFrame into a training set and a testing set based on the provided test size ratio. The split point is determined by calculating the index that corresponds to the test size ratio. The function returns the training set and testing set as separate DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47c92e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_distance(instance1, instance2):\n",
    "    # Euclidean distance\n",
    "    return np.sqrt(np.sum((instance1 - instance2) ** 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3356d962",
   "metadata": {},
   "source": [
    "Calculating Distance (calculate_distance): The calculate_distance function computes the Euclidean distance between two instances (instance1 and instance2). It uses NumPy's np.sqrt and np.sum functions to calculate the square root of the sum of squared differences between the corresponding feature values of the two instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "84468eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_nearest_neighbors(x_train, y_train, x_test, k):\n",
    "    y_pred = []\n",
    "    \n",
    "    for test_instance in x_test:\n",
    "        distances = []\n",
    "        \n",
    "        for i, train_instance in enumerate(x_train):\n",
    "            distance = calculate_distance(train_instance, test_instance)\n",
    "            distances.append((distance, y_train[i]))\n",
    "        \n",
    "        # Sort the distances in ascending order\n",
    "        distances.sort(key=lambda x: x[0])\n",
    "        \n",
    "        # Get the k nearest neighbors\n",
    "        neighbors = distances[:k]\n",
    "        \n",
    "        # Count the votes for each class label\n",
    "        votes = {}\n",
    "        for neighbor in neighbors:\n",
    "            label = neighbor[1]\n",
    "            if label in votes:\n",
    "                votes[label] += 1\n",
    "            else:\n",
    "                votes[label] = 1\n",
    "        \n",
    "        # Predict the class label with maximum votes\n",
    "        predicted_label = max(votes, key=votes.get)\n",
    "        y_pred.append(predicted_label)\n",
    "    \n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ce0242",
   "metadata": {},
   "source": [
    "K-Nearest Neighbors Algorithm (k_nearest_neighbors): The k_nearest_neighbors function performs the k-nearest neighbors classification algorithm. It takes the training features (x_train), training labels (y_train), test features (x_test), and the value of k as inputs. For each test instance, it calculates the distance to all training instances using calculate_distance and stores them in a list along with their corresponding labels. It then sorts the distances in ascending order and selects the k nearest neighbors. The function counts the votes for each class label among the k neighbors and predicts the class label with the maximum votes. The predicted labels for all test instances are stored in the y_pred list, which is returned by the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2bc77517",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_class_probabilities(x_train, y_train, x_test):\n",
    "    classes = np.unique(y_train)\n",
    "    class_probabilities = {}\n",
    "    \n",
    "    for class_label in classes:\n",
    "        class_instances = x_train[y_train == class_label]\n",
    "        class_probability = len(class_instances) / len(x_train)\n",
    "        \n",
    "        feature_probabilities = {}\n",
    "        for feature_index in range(x_train.shape[1]):\n",
    "            feature_values = class_instances[:, feature_index]\n",
    "            feature_probabilities[feature_index] = {\n",
    "                'mean': np.mean(feature_values),\n",
    "                'std': np.std(feature_values)\n",
    "            }\n",
    "        \n",
    "        class_probabilities[class_label] = {\n",
    "            'probability': class_probability,\n",
    "            'feature_probabilities': feature_probabilities\n",
    "        }\n",
    "    \n",
    "    return class_probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0870a03c",
   "metadata": {},
   "source": [
    "Computing Class Probabilities (compute_class_probabilities): The compute_class_probabilities function calculates the class probabilities and feature probabilities for the Naive Bayes algorithm. It takes the training features (x_train), training labels (y_train), and test features (x_test) as inputs. It first identifies the unique class labels in the training data using np.unique. Then, for each class label, it selects the instances belonging to that class and calculates the class probability as the ratio of the number of instances in that class to the total number of training instances. It also computes the mean and standard deviation of each feature within the class instances. The class probabilities and feature probabilities are stored in a dictionary and returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3cf6176b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_bayes(x_train, y_train, x_test):\n",
    "    y_pred = []\n",
    "    \n",
    "    class_probabilities = compute_class_probabilities(x_train, y_train, x_test)\n",
    "    \n",
    "    for test_instance in x_test:\n",
    "        instance_probabilities = {}\n",
    "        \n",
    "        for class_label, class_data in class_probabilities.items():\n",
    "            class_probability = class_data['probability']\n",
    "            feature_probabilities = class_data['feature_probabilities']\n",
    "            \n",
    "            instance_probability = class_probability\n",
    "            for feature_index, feature_value in enumerate(test_instance):\n",
    "                mean = feature_probabilities[feature_index]['mean']\n",
    "                std = feature_probabilities[feature_index]['std']\n",
    "                likelihood = (1 / (np.sqrt(2 * np.pi) * std)) * np.exp(-((feature_value - mean) ** 2) / (2 * std ** 2))\n",
    "                instance_probability *= likelihood\n",
    "            \n",
    "            instance_probabilities[class_label] = instance_probability\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec9cfab",
   "metadata": {},
   "source": [
    "Naive Bayes Algorithm (naive_bayes): The naive_bayes function applies the Naive Bayes algorithm to predict the class labels for the test instances. It takes the training features (x_train), training labels (y_train), and test features (x_test) as inputs. It first calls the compute_class_probabilities function to obtain the class probabilities and feature probabilities. Then, for each test instance, it iterates through each class label and calculates the instance probability based on the class probability and feature probabilities using the Naive Bayes formula. The instance probabilities for each class label are stored in the instance_probabilities dictionary."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
