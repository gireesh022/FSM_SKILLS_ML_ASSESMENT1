{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1766e9c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def linear_regression(x_train, y_train):\n",
    "    # Add a column of ones to x_train for the intercept term\n",
    "    ones = np.ones((x_train.shape[0], 1))\n",
    "    x_train = np.concatenate((ones, x_train), axis=1)\n",
    "\n",
    "    # Calculate the coefficients using the normal equation\n",
    "    x_transpose = np.transpose(x_train)\n",
    "    x_transpose_dot_x = np.dot(x_transpose, x_train)\n",
    "    x_transpose_dot_y = np.dot(x_transpose, y_train)\n",
    "    coefficients = np.dot(np.linalg.inv(x_transpose_dot_x), x_transpose_dot_y)\n",
    "\n",
    "    # Predict the values\n",
    "    y_pred = np.dot(x_train, coefficients)\n",
    "\n",
    "    # Calculate the mean squared error\n",
    "    mse = np.mean((y_pred - y_train) ** 2)\n",
    "\n",
    "    # Plot the data points and the regression line\n",
    "    plt.scatter(x_train[:, 1], y_train, color='b', label='Actual')\n",
    "    plt.plot(x_train[:, 1], y_pred, color='r', label='Predicted')\n",
    "    plt.xlabel('X')\n",
    "    plt.ylabel('Y')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    return coefficients, mse\n",
    "\n",
    "# Example usage\n",
    "# Assume we have a pandas DataFrame with two columns: 'X' (features) and 'Y' (output)\n",
    "# df = pd.read_csv('data.csv')\n",
    "# x_train = df[['X']].values\n",
    "# y_train = df['Y'].values\n",
    "# coefficients, mse = linear_regression(x_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c37724c",
   "metadata": {},
   "source": [
    "The linear_regression function takes in x_train (the features) and y_train (the output) as arguments.\n",
    "\n",
    "It adds a column of ones to x_train using NumPy's ones function. This is done to account for the intercept term in the linear regression equation.\n",
    "\n",
    "The coefficients are calculated using the normal equation, which involves taking the transpose of x_train, multiplying it with x_train, and then taking the inverse of the result. This is done using NumPy's transpose, dot, and linalg.inv functions.\n",
    "\n",
    "Next, the predicted values y_pred are calculated by multiplying x_train with the calculated coefficients.\n",
    "\n",
    "The mean squared error (MSE) is calculated by taking the mean of the squared difference between y_pred and y_train.\n",
    "\n",
    "The scatter plot is created using Matplotlib, where the actual data points are shown in blue and the predicted regression line is shown in red.\n",
    "\n",
    "The function returns the calculated coefficients and the MSE.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
